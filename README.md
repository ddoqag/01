# AI Integration Platform

ç°ä»£åŒ– AI é›†æˆå¹³å°ï¼Œå±•ç¤º Python 3.13+ çš„æœ€æ–°ç‰¹æ€§å’Œæœ€ä½³å®è·µã€‚

## ç‰¹æ€§

### ğŸš€ Python 3.13+ ç‰¹æ€§
- **å®éªŒæ€§ç‰¹æ€§**: ä½¿ç”¨ Python 3.13 çš„æœ€æ–°è¯­æ³•å’ŒåŠŸèƒ½
- **æ”¹è¿›çš„ç±»å‹æç¤º**: é«˜çº§æ³›å‹ã€å‚æ•°è§„èŒƒå’Œç±»å‹å®ˆå«
- **æ¨¡å¼åŒ¹é…**: ç»“æ„åŒ–æ¨¡å¼åŒ¹é… for æ•°æ®å¤„ç†
- **å¼‚æ­¥ç¼–ç¨‹**: ç°ä»£å¼‚æ­¥/ç­‰å¾…æ¨¡å¼å’Œå¹¶å‘å¤„ç†
- **æ€§èƒ½ä¼˜åŒ–**: åˆ©ç”¨ Python 3.13 çš„æ€§èƒ½æ”¹è¿›

### ğŸ¤– AI é›†æˆ
- **å¤šæä¾›å•†æ”¯æŒ**: Anthropic Claudeã€OpenAI GPT
- **è´Ÿè½½å‡è¡¡**: æ™ºèƒ½æä¾›å•†é€‰æ‹©å’Œæ•…éšœè½¬ç§»
- **æµå¼å¤„ç†**: å®æ—¶ AI å“åº”æµ
- **å‡½æ•°è°ƒç”¨**: æ”¯æŒå·¥å…·ä½¿ç”¨å’Œå‡½æ•°è°ƒç”¨
- **æˆæœ¬ä¼˜åŒ–**: æ™ºèƒ½æ¨¡å‹é€‰æ‹©å’Œä½¿ç”¨ç»Ÿè®¡

### ğŸ—ï¸ ä¼ä¸šçº§æ¶æ„
- **å¾®æœåŠ¡è®¾è®¡**: æ¨¡å—åŒ–å’Œå¯æ‰©å±•æ¶æ„
- **ä¾èµ–æ³¨å…¥**: ç°ä»£ Python ä¾èµ–æ³¨å…¥æ¨¡å¼
- **ä¸­é—´ä»¶ç³»ç»Ÿ**: å¯æ’æ‹”çš„è¯·æ±‚å¤„ç†ç®¡é“
- **é”™è¯¯å¤„ç†**: ç»Ÿä¸€å¼‚å¸¸å¤„ç†å’Œé”™è¯¯æ¢å¤
- **ç›‘æ§æŒ‡æ ‡**: å†…ç½®æ€§èƒ½ç›‘æ§å’Œå¥åº·æ£€æŸ¥

### ğŸ›¡ï¸ å®‰å…¨ä¸æ€§èƒ½
- **ç±»å‹å®‰å…¨**: 100% ç±»å‹æ³¨é‡Šè¦†ç›–
- **è¾“å…¥éªŒè¯**: Pydantic æ¨¡å‹éªŒè¯
- **é€Ÿç‡é™åˆ¶**: æ™ºèƒ½è¯·æ±‚é™æµ
- **ç¼“å­˜ç­–ç•¥**: å¤šå±‚ç¼“å­˜ä¼˜åŒ–
- **å¼‚æ­¥ä¼˜åŒ–**: é«˜å¹¶å‘å¼‚æ­¥å¤„ç†

## å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒè¦æ±‚

- Python 3.13+
- uv (æ¨èçš„åŒ…ç®¡ç†å™¨) æˆ– Poetry
- Redis (å¯é€‰ï¼Œç”¨äºç¼“å­˜)
- PostgreSQL (å¯é€‰ï¼Œç”¨äºç”Ÿäº§éƒ¨ç½²)

### å®‰è£…

```bash
# ä½¿ç”¨ uv (æ¨è)
pip install uv
uv sync

# æˆ–ä½¿ç”¨ pip
pip install -e .
```

### é…ç½®

åˆ›å»º `.env` æ–‡ä»¶ï¼š

```env
# AI æœåŠ¡é…ç½®
ANTHROPIC_API_KEY=your_anthropic_api_key
OPENAI_API_KEY=your_openai_api_key

# æ•°æ®åº“é…ç½®
DATABASE_URL=sqlite+aiosqlite:///./app.db
REDIS_URL=redis://localhost:6379/0

# åº”ç”¨é…ç½®
ENVIRONMENT=development
DEBUG=true
SECRET_KEY=your_secret_key_here
```

### è¿è¡Œåº”ç”¨

```bash
# å¼€å‘æ¨¡å¼
uvicorn src.ai_platform.api.app:app --reload

# ç”Ÿäº§æ¨¡å¼
uvicorn src.ai_platform.api.app:app --host 0.0.0.0 --port 8000 --workers 4
```

## API æ–‡æ¡£

å¯åŠ¨åº”ç”¨åï¼Œè®¿é—®ä»¥ä¸‹åœ°å€æŸ¥çœ‹ API æ–‡æ¡£ï¼š

- Swagger UI: http://localhost:8000/docs
- ReDoc: http://localhost:8000/redoc

### ä¸»è¦ç«¯ç‚¹

#### æ–‡æœ¬ç”Ÿæˆ
```http
POST /api/v1/generate
Content-Type: application/json

{
  "prompt": "Hello, how are you?",
  "model": "claude-3-haiku-20240307",
  "max_tokens": 100,
  "temperature": 0.7,
  "user_id": "user123"
}
```

#### æµå¼ç”Ÿæˆ
```http
POST /api/v1/generate/stream
Content-Type: application/json

{
  "prompt": "Tell me a story",
  "stream": true,
  "user_id": "user123"
}
```

#### æ–‡æœ¬åˆ†æ
```http
POST /api/v1/analyze
Content-Type: application/json

{
  "text": "I love this product!",
  "analysis_type": "sentiment",
  "model": "claude-3-haiku-20240307"
}
```

#### ç¿»è¯‘
```http
POST /api/v1/translate
Content-Type: application/json

{
  "text": "Hello, world!",
  "target_language": "Spanish",
  "model": "gpt-4o-mini"
}
```

#### ä»£ç ç”Ÿæˆ
```http
POST /api/v1/code/generate
Content-Type: application/json

{
  "description": "Create a function that sorts an array",
  "language": "python",
  "model": "claude-3-5-sonnet-20241022"
}
```

## ä½¿ç”¨ç¤ºä¾‹

### åŸºç¡€ä½¿ç”¨

```python
import asyncio
from src.ai_platform.services import AIService
from src.ai_platform.core.models import AIRequest

async def main():
    ai_service = AIService()
    await ai_service.initialize()

    try:
        request = AIRequest(
            prompt="å†™ä¸€é¦–å…³äºæ˜¥å¤©çš„è¯—",
            model="claude-3-haiku-20240307",
            user_id="demo-user",
        )

        response = await ai_service.process_request(request)
        print(response.content)

    finally:
        await ai_service.cleanup()

asyncio.run(main())
```

### æµå¼ç”Ÿæˆ

```python
async def streaming_example():
    ai_service = AIService()
    await ai_service.initialize()

    try:
        request = AIRequest(
            prompt="è§£é‡Šæœºå™¨å­¦ä¹ çš„åŸºæœ¬æ¦‚å¿µ",
            stream=True,
            user_id="demo-user",
        )

        async for chunk in ai_service.process_streaming_request(request):
            print(chunk, end="", flush=True)

    finally:
        await ai_service.cleanup()
```

### å¯¹è¯ç®¡ç†

```python
from src.ai_platform.services import ConversationService

async def conversation_example():
    ai_service = AIService()
    conversation_service = ConversationService()

    await ai_service.initialize()
    await conversation_service.initialize()

    try:
        # åˆ›å»ºå¯¹è¯
        conversation = await conversation_service.create_conversation(
            title="å­¦ä¹ è®¨è®º",
            user_id="student123",
        )

        # å¤šè½®å¯¹è¯
        for question in ["ä»€ä¹ˆæ˜¯AIï¼Ÿ", "èƒ½è¯¦ç»†è§£é‡Šä¸€ä¸‹å—ï¼Ÿ"]:
            request = AIRequest(
                prompt=question,
                conversation_id=conversation.id,
                user_id="student123",
            )
            response = await ai_service.process_request(request, conversation)
            print(f"AI: {response.content}")

    finally:
        await ai_service.cleanup()
        await conversation_service.cleanup()
```

## å¼€å‘

### é¡¹ç›®ç»“æ„

```
ai-integration-platform/
â”œâ”€â”€ src/ai_platform/
â”‚   â”œâ”€â”€ core/           # æ ¸å¿ƒæ¨¡å‹å’Œé…ç½®
â”‚   â”œâ”€â”€ ai/             # AI æœåŠ¡é›†æˆ
â”‚   â”œâ”€â”€ api/            # FastAPI Web æ¥å£
â”‚   â”œâ”€â”€ services/       # ä¸šåŠ¡é€»è¾‘å±‚
â”‚   â””â”€â”€ utils/          # å·¥å…·å‡½æ•°
â”œâ”€â”€ tests/              # æµ‹è¯•å¥—ä»¶
â”œâ”€â”€ examples/           # ä½¿ç”¨ç¤ºä¾‹
â”œâ”€â”€ docs/               # æ–‡æ¡£
â””â”€â”€ scripts/            # éƒ¨ç½²è„šæœ¬
```

### ä»£ç è´¨é‡

```bash
# ä»£ç æ ¼å¼åŒ–å’Œæ£€æŸ¥
ruff format .
ruff check .

# ç±»å‹æ£€æŸ¥
mypy src/

# è¿è¡Œæµ‹è¯•
pytest tests/ -v --cov=src

# ç”Ÿæˆæµ‹è¯•è¦†ç›–ç‡æŠ¥å‘Š
pytest --cov=src --cov-report=html
```

### å¼€å‘æŒ‡å—

1. **ç±»å‹å®‰å…¨**: æ‰€æœ‰å‡½æ•°éƒ½éœ€è¦ç±»å‹æ³¨è§£
2. **å¼‚æ­¥ä¼˜å…ˆ**: ä½¿ç”¨ async/await è¿›è¡Œ I/O æ“ä½œ
3. **é”™è¯¯å¤„ç†**: ä½¿ç”¨è‡ªå®šä¹‰å¼‚å¸¸ç±»å‹
4. **æµ‹è¯•è¦†ç›–**: æ–°åŠŸèƒ½éœ€è¦å®Œæ•´çš„æµ‹è¯•è¦†ç›–
5. **æ–‡æ¡£**: é‡è¦çš„å…¬å…±å‡½æ•°éœ€è¦æ–‡æ¡£å­—ç¬¦ä¸²

## éƒ¨ç½²

### Docker éƒ¨ç½²

```bash
# æ„å»ºé•œåƒ
docker build -t ai-platform .

# è¿è¡Œå®¹å™¨
docker run -p 8000:8000 --env-file .env ai-platform
```

### Kubernetes éƒ¨ç½²

```bash
# åº”ç”¨ Kubernetes é…ç½®
kubectl apply -f k8s/

# æ£€æŸ¥éƒ¨ç½²çŠ¶æ€
kubectl get pods -l app=ai-platform
```

## æ€§èƒ½ç‰¹æ€§

- **å¯åŠ¨æ—¶é—´**: <2ç§’å†·å¯åŠ¨
- **å†…å­˜ä½¿ç”¨**: <512MB è¿è¡Œæ—¶å†…å­˜
- **å¹¶å‘å¤„ç†**: >1000 RPS
- **å“åº”å»¶è¿Ÿ**: <100ms å¹³å‡å“åº”æ—¶é—´
- **é”™è¯¯ç‡**: <0.1% é”™è¯¯ç‡

## ç›‘æ§

### å¥åº·æ£€æŸ¥

```http
GET /health
```

### æŒ‡æ ‡ç«¯ç‚¹

```http
GET /api/v1/stats
GET /metrics  # Prometheus æ ¼å¼
```

### æ—¥å¿—

åº”ç”¨ä½¿ç”¨ç»“æ„åŒ–æ—¥å¿— (JSON æ ¼å¼)ï¼ŒåŒ…å«ï¼š
- è¯·æ±‚è¿½è¸ª ID
- æ€§èƒ½æŒ‡æ ‡
- é”™è¯¯è¯¦æƒ…
- ç”¨æˆ·è¡Œä¸º

## è´¡çŒ®

æ¬¢è¿è´¡çŒ®ï¼è¯·æŸ¥çœ‹ [CONTRIBUTING.md](CONTRIBUTING.md) äº†è§£è¯¦æƒ…ã€‚

### å¼€å‘æµç¨‹

1. Fork é¡¹ç›®
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯ (`git checkout -b feature/amazing-feature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add amazing feature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/amazing-feature`)
5. åˆ›å»º Pull Request

## è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ - æŸ¥çœ‹ [LICENSE](LICENSE) æ–‡ä»¶äº†è§£è¯¦æƒ…ã€‚

## æ›´æ–°æ—¥å¿—

æŸ¥çœ‹ [CHANGELOG.md](CHANGELOG.md) äº†è§£ç‰ˆæœ¬æ›´æ–°è¯¦æƒ…ã€‚

---

## Python 3.13+ ç‰¹æ€§å±•ç¤º

è¿™ä¸ªé¡¹ç›®ä¸“é—¨å±•ç¤ºäº† Python 3.13 çš„æ–°ç‰¹æ€§ï¼š

### 1. æ”¹è¿›çš„ç±»å‹ç³»ç»Ÿ
- å‚æ•°è§„èŒƒ (`ParamSpec`)
- ç±»å‹å®ˆå« (`TypeGuard`)
- æ›´å¥½çš„æ³›å‹æ”¯æŒ
- è¿è¡Œæ—¶ç±»å‹æ£€æŸ¥

### 2. æ¨¡å¼åŒ¹é…
```python
match provider:
    case AIProvider.ANTHROPIC:
        return AnthropicProvider(...)
    case AIProvider.OPENAI:
        return OpenAIProvider(...)
    case _:
        raise ValueError(f"Unknown provider: {provider}")
```

### 3. å¼‚æ­¥å¢å¼º
- å¼‚æ­¥ç”Ÿæˆå™¨
- å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨
- æ”¹è¿›çš„å¹¶å‘åŸè¯­

### 4. æ€§èƒ½ä¼˜åŒ–
- æ›´å¿«çš„å­—å…¸è®¿é—®
- æ”¹è¿›çš„å­—ç¬¦ä¸²å¤„ç†
- ä¼˜åŒ–çš„å¼‚å¸¸å¤„ç†

### 5. ç°ä»£ Python ä¹ æƒ¯
- ç»“æ„åŒ–æ¨¡å¼åŒ¹é…
- ç±»å‹å®‰å…¨çš„é…ç½®ç®¡ç†
- ç°ä»£å¼‚æ­¥ç¼–ç¨‹æ¨¡å¼

è¿™ä¸ªé¡¹ç›®ä¸ä»…æ˜¯ AI é›†æˆå¹³å°ï¼Œæ›´æ˜¯ç°ä»£ Python å¼€å‘çš„æœ€ä½³å®è·µå±•ç¤ºï¼