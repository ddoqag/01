#!/usr/bin/env python3
"""
DZHçœŸå®AIè‚¡ç¥¨åˆ†æå·¥å…·
é›†æˆåŠ¨æ€Tokenå’ŒHTMLå†…å®¹æå– - å•æ–‡ä»¶ç‰ˆæœ¬
"""

import json
import sys
import requests
import urllib.parse
from pathlib import Path
from datetime import datetime
import re
import html
from bs4 import BeautifulSoup

class DZHRealAnalysis:
    """DZHçœŸå®è‚¡ç¥¨åˆ†æå·¥å…·"""

    def __init__(self):
        self.config_path = Path(__file__).parent / "settings.local.json"
        self.token = self.load_token()

    def load_token(self):
        """åŠ è½½Token"""
        try:
            with open(self.config_path, 'r', encoding='utf-8') as f:
                settings = json.load(f)
                return settings.get("deepseek", {}).get("api_key", "")
        except:
            return ""

    def extract_ai_response(self, html_content: str) -> dict:
        """æå–AIå›å¤å†…å®¹"""
        try:
            decoded_content = html.unescape(html_content)
            soup = BeautifulSoup(decoded_content, 'html.parser')

            # æŸ¥æ‰¾JSONæ•°æ®
            json_patterns = [
                r'window\.INITIAL_STATE\s*=\s*({.*?});',
                r'window\.AI_RESPONSE\s*=\s*({.*?});',
                r'window\.APP_DATA\s*=\s*({.*?});',
            ]

            for pattern in json_patterns:
                matches = re.findall(pattern, decoded_content, re.DOTALL | re.IGNORECASE)
                for match in matches:
                    try:
                        json_str = match.strip().rstrip(';')
                        data = json.loads(json_str)

                        # æŸ¥æ‰¾AIå›å¤
                        ai_text = self._find_ai_text_in_json(data)
                        if ai_text:
                            return {
                                "success": True,
                                "response": ai_text,
                                "method": "json_extraction",
                                "confidence": 0.9
                            }
                    except:
                        continue

            # CSSé€‰æ‹©å™¨æå–
            selectors = [
                '.ai-response', '.chat-message', '.deepseek-answer', '.ai-answer',
                '#ai-response', '#chat-answer', '[data-response]', '[data-answer]',
                '.response-content', '.answer-content', '.message-content',
                'article', '.content', '.main-content'
            ]

            for selector in selectors:
                elements = soup.select(selector)
                for element in elements:
                    text = self._clean_text(element.get_text())
                    if self._is_ai_response(text):
                        return {
                            "success": True,
                            "response": text,
                            "method": "css_selector",
                            "confidence": 0.8,
                            "selector": selector
                        }

            # æ™ºèƒ½æ–‡æœ¬æå–
            candidates = []
            for element in soup.find_all(['div', 'p', 'span', 'article', 'section']):
                text = self._clean_text(element.get_text())
                if len(text) > 50:
                    score = self._calculate_ai_score(text, element)
                    candidates.append({'text': text, 'score': score})

            if candidates:
                best = max(candidates, key=lambda x: x['score'])
                if best['score'] > 0.3:
                    return {
                        "success": True,
                        "response": best['text'],
                        "method": "smart_extraction",
                        "confidence": best['score']
                    }

            return {
                "success": False,
                "error": "æ— æ³•æå–AIå›å¤å†…å®¹",
                "html_length": len(html_content)
            }

        except Exception as e:
            return {
                "success": False,
                "error": f"è§£æå¤±è´¥: {str(e)}"
            }

    def _find_ai_text_in_json(self, data, depth=0) -> str:
        """åœ¨JSONä¸­æŸ¥æ‰¾AIæ–‡æœ¬"""
        if depth > 5:
            return None

        if isinstance(data, dict):
            ai_keys = ['response', 'answer', 'content', 'message', 'text', 'data']
            for key in ai_keys:
                if key in data:
                    value = data[key]
                    if isinstance(value, str) and self._is_ai_response(value):
                        return value
                    elif isinstance(value, (dict, list)):
                        result = self._find_ai_text_in_json(value, depth + 1)
                        if result:
                            return result

            for value in data.values():
                if isinstance(value, (dict, list)):
                    result = self._find_ai_text_in_json(value, depth + 1)
                    if result:
                        return result

        elif isinstance(data, list):
            for item in data:
                if isinstance(item, str) and self._is_ai_response(item):
                    return item
                elif isinstance(item, (dict, list)):
                    result = self._find_ai_text_in_json(item, depth + 1)
                    if result:
                        return result

        return None

    def _clean_text(self, text: str) -> str:
        """æ¸…ç†æ–‡æœ¬"""
        if not text:
            return ""
        text = re.sub(r'\s+', ' ', text)
        return text.strip()

    def _is_ai_response(self, text: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦æ˜¯AIå›å¤"""
        if not text or len(text) < 20:
            return False

        ai_keywords = [
            'æ‚¨å¥½', 'ä½ å¥½', 'æ ¹æ®', 'åˆ†æ', 'å»ºè®®', 'è®¤ä¸º', 'é¢„æµ‹',
            'æ€»çš„æ¥è¯´', 'é¦–å…ˆ', 'å…¶æ¬¡', 'æ­¤å¤–', 'æœ€å', 'æŠ•èµ„å»ºè®®',
            'æŠ€æœ¯åˆ†æ', 'åŸºæœ¬é¢', 'å¸‚åœºè¶‹åŠ¿', 'é£é™©æç¤º', 'æ“ä½œç­–ç•¥',
            'ä»·æ ¼', 'è‚¡ç¥¨', 'èµ°åŠ¿', 'æ”¯æ’‘', 'é˜»åŠ›', 'ä¹°å…¥', 'å–å‡º'
        ]

        text_lower = text.lower()
        count = sum(1 for keyword in ai_keywords if keyword in text_lower)
        return count >= 3

    def _calculate_ai_score(self, text: str, element) -> float:
        """è®¡ç®—AIæ–‡æœ¬å¾—åˆ†"""
        score = 0.0

        if len(text) > 100:
            score += 0.2
        if len(text) > 300:
            score += 0.2

        text_lower = text.lower()
        ai_keywords = ['æ‚¨å¥½', 'åˆ†æ', 'å»ºè®®', 'é¢„æµ‹', 'ä»·æ ¼', 'è‚¡ç¥¨', 'æŠ€æœ¯', 'é£é™©']
        keyword_count = sum(1 for keyword in ai_keywords if keyword in text_lower)
        score += min(keyword_count * 0.15, 0.4)

        classes = str(element.get('class', [])).lower()
        element_id = str(element.get('id', '')).lower()
        if any(word in classes for word in ['ai', 'response', 'answer', 'chat']):
            score += 0.3
        if any(word in element_id for word in ['ai', 'response', 'answer', 'chat']):
            score += 0.3

        return min(score, 1.0)

    def analyze_stock(self, stock_code: str, question: str) -> dict:
        """åˆ†æè‚¡ç¥¨"""
        if not self.token or len(self.token) < 20:
            return {"success": False, "error": "Tokenæ— æ•ˆ"}

        base_url = "https://f.dzh.com.cn/zswd/newask"
        params = {
            "tun": "dzhsp846",
            "token": self.token,
            "version": "1.0",
            "scene": "gg",
            "sceneName": "è‚¡ç¥¨åˆ†æ",
            "sceneCode": "STOCK_ANALYSIS"
        }

        url = f"{base_url}?{urllib.parse.urlencode(params)}"
        full_question = f"è¯·å¯¹è‚¡ç¥¨{stock_code}è¿›è¡Œè¯¦ç»†åˆ†æï¼š{question}"

        data = {
            "question": full_question,
            "timestamp": datetime.now().isoformat(),
            "client": "dzh_real_analysis",
            "stock_code": stock_code
        }

        headers = {
            'Content-Type': 'application/json',
            'User-Agent': 'DZH-DeepSeek-Analysis/2.0.0',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Referer': 'https://f.dzh.com.cn/'
        }

        try:
            print(f"ğŸš€ æ­£åœ¨è¯·æ±‚DZH APIåˆ†æ {stock_code}...")
            print(f"ğŸ“ é—®é¢˜: {question}")
            print(f"ğŸ”‘ Token: {self.token[:20]}...({len(self.token)}å­—ç¬¦)")

            response = requests.post(url, json=data, headers=headers, timeout=30)

            print(f"ğŸ“Š å“åº”çŠ¶æ€: {response.status_code}")

            if response.status_code == 200:
                content = response.text
                print(f"ğŸ“„ å“åº”é•¿åº¦: {len(content)}å­—ç¬¦")

                # æå–AIå›å¤
                extraction_result = self.extract_ai_response(content)

                if extraction_result.get("success"):
                    return {
                        "success": True,
                        "stock_code": stock_code,
                        "question": question,
                        "response": extraction_result["response"],
                        "method": extraction_result["method"],
                        "confidence": extraction_result.get("confidence", 0.5),
                        "timestamp": datetime.now().isoformat()
                    }
                else:
                    return {
                        "success": False,
                        "stock_code": stock_code,
                        "error": f"AIå†…å®¹æå–å¤±è´¥: {extraction_result.get('error', 'æœªçŸ¥é”™è¯¯')}",
                        "html_length": len(content)
                    }
            else:
                return {
                    "success": False,
                    "error": f"HTTPé”™è¯¯: {response.status_code}"
                }

        except Exception as e:
            return {
                "success": False,
                "error": f"è¯·æ±‚å¤±è´¥: {str(e)}"
            }

    def format_analysis_report(self, result: dict) -> str:
        """æ ¼å¼åŒ–åˆ†ææŠ¥å‘Š"""
        if not result.get("success"):
            return f"âŒ åˆ†æå¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}"

        output = []
        output.append("ğŸ“ˆ DZH AIè‚¡ç¥¨åˆ†ææŠ¥å‘Š")
        output.append("=" * 60)
        output.append(f"ğŸ¢ è‚¡ç¥¨ä»£ç : {result['stock_code']}")
        output.append(f"ğŸ“… åˆ†ææ—¶é—´: {result['timestamp'][:19].replace('T', ' ')}")
        output.append(f"ğŸ“ åˆ†æé—®é¢˜: {result['question']}")
        output.append(f"ğŸ”§ æå–æ–¹æ³•: {result['method']}")
        output.append(f"ğŸ¯ ç½®ä¿¡åº¦: {result.get('confidence', 0.5):.1%}")
        output.append("")

        # AIåˆ†æå†…å®¹
        output.append("ğŸ¤– DZH AIåˆ†æ:")
        output.append("-" * 50)
        response = result['response']
        display_text = response[:1000] + "..." if len(response) > 1000 else response
        output.append(display_text)
        output.append("")

        # æå–ä»·æ ¼ä¿¡æ¯
        prices = self._extract_prices(result['response'])
        if prices:
            output.append("ğŸ’° ä»·æ ¼ä¿¡æ¯:")
            output.append("-" * 30)
            for key, value in prices.items():
                output.append(f"  {key}: {value}")
            output.append("")

        # æŠ•èµ„å»ºè®®
        suggestions = self._extract_suggestions(result['response'])
        if suggestions:
            output.append("ğŸ’¡ æŠ•èµ„å»ºè®®:")
            output.append("-" * 30)
            for suggestion in suggestions[:5]:
                output.append(f"  â€¢ {suggestion}")
            output.append("")

        output.append("âš ï¸  å…è´£å£°æ˜: æœ¬åˆ†æä»…ä¾›å‚è€ƒï¼ŒæŠ•èµ„éœ€è°¨æ…")
        output.append("ğŸ“Š æ•°æ®æ¥æº: DZH DeepSeek AIåˆ†æç³»ç»Ÿ")

        return "\n".join(output)

    def _extract_prices(self, text: str) -> dict:
        """æå–ä»·æ ¼ä¿¡æ¯"""
        prices = {}
        patterns = [
            (r'å½“å‰ä»·.*?(\d+\.?\d*)', 'å½“å‰ä»·'),
            (r'ç›®æ ‡ä»·.*?(\d+\.?\d*)', 'ç›®æ ‡ä»·'),
            (r'æ”¯æ’‘ä½.*?(\d+\.?\d*)', 'æ”¯æ’‘ä½'),
            (r'é˜»åŠ›ä½.*?(\d+\.?\d*)', 'é˜»åŠ›ä½'),
            (r'é¢„æµ‹.*?(\d+\.?\d*)', 'é¢„æµ‹ä»·'),
        ]

        for pattern, label in patterns:
            matches = re.findall(pattern, text)
            if matches:
                prices[label] = f"Â¥{matches[0]}"

        return prices

    def _extract_suggestions(self, text: str) -> list:
        """æå–æŠ•èµ„å»ºè®®"""
        suggestions = []
        sentences = re.split(r'[ã€‚ï¼ï¼Ÿ]', text)

        for sentence in sentences:
            sentence = sentence.strip()
            if len(sentence) > 10:
                if any(keyword in sentence for keyword in ['å»ºè®®', 'æ¨è', 'æ“ä½œ', 'æ³¨æ„', 'é£é™©', 'ä¹°å…¥', 'å–å‡º']):
                    suggestions.append(sentence + 'ã€‚')

        return suggestions

def main():
    """ä¸»å‡½æ•°"""
    if len(sys.argv) < 3:
        print("ğŸ”§ DZHçœŸå®AIè‚¡ç¥¨åˆ†æå·¥å…·")
        print("ç”¨æ³•: python dzh_real_analysis.py <è‚¡ç¥¨ä»£ç > <é—®é¢˜>")
        print("ç¤ºä¾‹: python dzh_real_analysis.py 000042 æ˜å¤©ä»·æ ¼é¢„æµ‹")
        return

    stock_code = sys.argv[1]
    question = " ".join(sys.argv[2:])

    analyzer = DZHRealAnalysis()

    print(f"ğŸ”® DZH AIè‚¡ç¥¨åˆ†æ - {stock_code}")
    print("=" * 60)

    # æ‰§è¡Œåˆ†æ
    result = analyzer.analyze_stock(stock_code, question)

    # ç”ŸæˆæŠ¥å‘Š
    report = analyzer.format_analysis_report(result)
    print(report)

if __name__ == "__main__":
    main()